\documentclass[../cheatSheetAlgoritmi.tex]{subfiles}
\begin{document}

\section{Programmazione dinamica e memoization}
\subsection{Programmazione dinamica}
\textbf{Introduzione} Tecnica classica di risoluzione dei problemi che consiste nello spezzare il problema ricorsivamente in sottoproblemi. A differenza della tecnica del divide-et-impera, ogni sotto problema viene risolto solo una volta e la sua soluzione viene memorizzata in una tabella. Nel caso bisognasse risolvere nuovamente il sottoproblema, si ottiene la soluzione facendo un semplice accesso alla tabella senza effettuare di nuovo il calcolo. La tabella ha un costo di lookup pari a  $\mathcal{O}$(1). 

\subsubsection{Domino}
\textbf{Problema:} Il gioco del domino è basato su tessere di dimensione $2\times1$. Scrivere un algoritmo efficiente che prenda in input un intero n e restituisca il numero di possibili disposizioni di n tessere in un rettangolo $2\times n$. \\\\
\textbf{Soluzione:} Iniziamo a considerare alcuni casi per definire una soluzione. Con $n=0$ abbiamo solo una disposizione possibile (nessuna tessera), con $n=1$ abbiamo solo una disposizione possibile (tessera messa in verticale). L'ultima tessera può essere disposta in due modi: se la posiziono in verticale devo risolvere il problema con dimensione $n-1$, mentre se la metto in orizzontale devo per forza mettere 2 tessere e risolvere il problema di dimensione $n-2$. In generale la soluzione ha la seguente forma: 

\begin{equation*}
  	DP[n] =\begin{cases}
    	1 & \text{$n \leq 1$}\\
    	DP[n-2] + DP[n-1] & \text{$n > 1$}
  	\end{cases}
\end{equation*}\\\\
Notiamo che il risultato è la sequenza di Fibonacci: 1, 1, 2, 3, 5, 8, ... \\
Proponiamo 3 soluzioni al problema:
\begin{itemize}
	\item domino1(): soluzione ricorsiva che non fa uso della programmazione dinamica e risolve più volte gli stessi sottoproblemi
	\item domino2(): soluzione con programmazione dinamica che memorizza il risultato in una tabella DP. L'approccio è bottom-up cioè si parte risolvendo i casi base e risalendo si risolvono problemi sempre più grandi. La tabella $DP$ in questo caso memorizza il risultato per ogni sottoproblema con dimensione tra 0 e $n$.
	\item domino3(): la soluzione proposta è uguale alla precedente con la differenza che l'uso di memoria è ridotto salvando solo la soluzione degli ultimi 3 sottoproblemi. 
\end{itemize}
\newpage
\noindent
\textbf{Implementazione:}
\begin{lstlisting}[ caption= Domino/Fibonacci versione $\mathcal{O}(2^n)$]
int domino1(int n)
	if n $\leq$ 1 then
		return 1
	else
		return domino1(n - 1) + domino1(n - 2)
\end{lstlisting}

\begin{lstlisting}[ caption= Domino/Fibonacci versione $\mathcal{O}(n^2)$ in tempo e spazio]
int domino2(int n)
	DP = new int[0...n]
	DP[0] = DP[1] = 1
	for i = 2 to n do
		DP[i] = DP[i - 1] + DP[i - 2]
	return DP[n]
\end{lstlisting}

\begin{lstlisting}[ caption= Domino/Fibonacci versione $\mathcal{O}(n^2)$ in tempo $\mathcal{O}(n)$ e spazio]
int domino3(int n)
	int $DP_0$ = 1
	int $DP_1$ = 1
	int $DP_2$ = 1
	for i = 2 to n do
		$DP_0$ = $DP_1$
		$DP_1$ = $DP_2$
		$DP_2$ = $DP_0$ + $DP_1$
	return $DP_2$
\end{lstlisting}
\textbf{Complessità:} Per calcolare la complessità dobbiamo usare il modello di costo logaritmico che tiene consto lo spazio necessario per salvare un numero della sequenza di Fibonacci ($\Theta(n)$) e il costo per sommare due numeri consecutivi della sequenza ($\Theta(n)$). 
Il costo per le varie versioni è il seguente: 
\begin{center}
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{ |c|c|c| } 
		\hline
			Funzione & Complessità (Tempo) & Complessità (Spazio)\\ 
		\hline
			domino1() & $\mathcal{O}$(n$2^{n}$) &  $\mathcal{O}$($n^{2}$)\\ 
		\hline
			domino2() &  $\mathcal{O}$($n^{2}$) &  $\mathcal{O}$($n^{2}$) \\
		\hline
			domino3() &  $\mathcal{O}$($n^{2}$) &  $\mathcal{O}$(n) \\
		\hline
	\end{tabular}
\end{center} \


\subsubsection{Hateville}
\textbf{Problema:} Hateville è un villaggio particolare, composto da $n$ case, numerate da 1 a $n$ lungo una singola strada. Ad Hateville ognuno odia i propri vicini della porta accanto, da entrambi i lati. Quindi, il vicino i odia i vicini $i-1$ e $i+1$ (se esistenti).
Hateville vuole organizzare una sagra e vi ha affidato il compito di
raccogliere i fondi. Ogni abitante i ha intenzione di donare una quantità $D[i]$, ma non intende partecipare ad una raccolta fondi a cui partecipano uno o entrambi i propri vicini. Scrivere un algoritmo che restituisca il sottoinsieme di indici S  $\subseteq$ $\{$1, ..., n $\}$ tale per cui la donazione totale T = $\sum\limits_{i \in S} {D[i]}$ è massimale. 
\newpage
\begin{flushleft}
\textbf{Soluzione:} Definiamo il problema in questi termini: 
\end{flushleft}
\begin{itemize}
	\item Sia $HV(i)$ uno dei possibili insiemi di indici da selezionare per ottenere una donazione ottimale dalle prime i case di Hateville, numerate $[1...n]$
	\item $HV(n)$ è la soluzione del problema originale
	\item Se non accetto la donazione $i$-esima: $HV(i) = HV(i-1)$
	\item Se accetto la donazione i-esima: $HV(i) = i \cup HV(i-2)$
	\item Per decidere se accettare una donazione $i$: $HV(i) = highest(HV(i -1),  \{i\} \cup HV(i-2))$
	\item Casi base: HV(0) = $\emptyset$ e HV(1) = $\{$1$\}$ \\
\end{itemize} 
Mettendo tutto insieme otteniamo:
\begin{equation*}
  	HV(i) =\begin{cases}
    	\emptyset & \text{$i = 0$}\\
    	\{1\} & \text{$i = 1$}\\
    	highest(HV(i -1), \{i\} \cup HV(i-2)) & \text{$i \ge 2$}
  	\end{cases}
\end{equation*} \\
Per riuscire a calcolare l'insieme delle soluzioni dobbiamo prima calcolare il valore della soluzione massimale usando la programmazione dinamica e poi ricostruiamo la soluzione partendo da questo valore. La ricorrenza per trovare il valore massimale con la programmazione dinamica è la seguente:

\begin{equation*}
  	DP[i] =\begin{cases}
    	0 & \text{$i = 0$}\\
    	D[1] & \text{$i = 1$}\\
    	max(DP[i -1], DP[i-2]+D[i]) & \text{$i \ge 2$}
  	\end{cases}
\end{equation*} \\\\
\textbf{Implementazione:}
\begin{lstlisting}[ caption= Hateville versione $\mathcal{O}(n)$ senza calcolo della soluzione]
int hateville(int[] D, int n)
	int[] DP = new int[0...n]
	DP[0] = 0
	DP[1] = D[1]
	for i = 2 to n do
		DP[i] = max(DP[i - 1], DP[i - 2] + D[i])
	return DP[n]
\end{lstlisting}

\begin{lstlisting}[ caption= Soluzione di Hateville versione $\mathcal{O}(n)$]
SET solution(int[] DP, int[] D, int i)
	if i == 0 then
		return $\emptyset$
	else if i $==$ 1 then
		return {1}
	else if DP[i] $==$ DP[ i - 1]  then
		return solution(DP, D, i  - 1)
	else
		SET sol = solution(DP, D, i - 2)
		sol.insert(i)
		return sol
\end{lstlisting}

\begin{lstlisting}[ caption= Hateville versione $\mathcal{O}(n)$ completa]
int hateville(int[] D, int n)
	int[] DP = new int[0...n]
	DP[0] = 0
	DP[1] = D[1]
	for i = 2 to n do
		DP[i] = max(DP[i - 1], DP[i - 2] + D[i])
	print DP[n]
	return solution(DP, D, n)
\end{lstlisting}
\textbf{Complessità:}  
\begin{itemize}
	\item Complessità solution(): $\Theta(n)$
	\item Complessità hateville() (sia per tempo che per spazio): $\Theta(n)$
\end{itemize}
\subsubsection{Zaino (Knapsack)}
\textbf{Problema:} Dato un insieme di oggetti, ognuno caratterizzato da un peso e un
profitto, e uno "zaino" con un limite di capacità, individuare un
sottoinsieme di oggetti: 
\begin{itemize}
	\item il cui peso sia inferiore alla capacità dello zaino;
	\item il valore totale degli oggetti sia massimale, i.e. più alto o uguale al valore di qualunque altro sottoinsieme di oggetti
\end{itemize} 
Siano dati in input: 
\begin{itemize}
	\item Vettore $w$, dove $w[i]$ è il peso (weight) dell’oggetto $i$-esimo
	\item Vettore $p$, dove $p[i]$ è il profitto (profit) dell’oggetto $i$-esimo
	\item La capacità $C$ dello zaino
\end{itemize} 
L'output deve essere un insieme $S  \subseteq \{1, ..., n \}$ tale che:
\begin{itemize}
	\item Il volume totale deve essere minore o uguale alla capacità 
	\item Il profitto totale deve essere massimizzato\\
\end{itemize} 
\textbf{Soluzione:} Dato uno zaino di capacità $C$ e $n$ oggetti caratterizzati da peso $w$ e profitto $p$, definiamo $DP[i][c]$ come il massimo profitto che può essere ottenuto dai primi $i \leq n$ oggetti contenuti in uno zaino di
capacità $c \leq C$. Il massimo profitto ottenibile per il problema originale è rappresentato da $DP[n][C]$.\\
Considerando i vari casi (prendere o meno l'ultimo elemento e i vari casi base) otteniamo la seguente formula ricorsiva: 
\begin{equation*}
  	DP[i][c] =\begin{cases}
    	0 & \text{$i = 0$  or  $c = 0$}\\
    	-\infty & \text{$c < 0$}\\
    	max(DP[i -1][c-w[i]]+p[i], DP[i-1][c]) & \text{$altrimenti$}
  	\end{cases}
\end{equation*}
\newpage
\noindent
\textbf{Implementazione:}
\begin{lstlisting}[ caption= Knapsack versione $\mathcal{O}(nC)$ con programmazione dinamica]
int knapsack(int[] w, int[] p, int n, int C)
	int[][] DP = new int[0...n][0...n]
	for i = 0 to n do
		DP[i][0] = 0
	for c = 0 to n do
		DP[0][c] = 0
	for i = 1 to n do
		for c = 1 to C do
			if w[i] $\leq$ c then
				DP[i][c] = max(DP[i - 1][c - w[i]] + p[i], DP[i - 1][c])
			else
					DP[i][c] = DP[i - 1][c]
	return DP[n][C]
\end{lstlisting}
\textbf{Complessità:} La complessità dell'algoritmo è $\mathcal{O}(nC)$, ma se consideriamo che sono necessari $k = \log C$ bit per rappresentare $C$, la complessità diventa \textcolor{red}{$pseudo-polinomiale$} e vale $T(n) = \mathcal{O}(n2^{k})$.
La versione ricorsiva che non fa uso della memorizzazione costa $\mathcal{O}(2^{n})$. Questo è un problema \emph{NP completo}.
\subsection{Memoization}
\textbf{Introduzione}\\
Non tutte le soluzioni dei sottoproblemi possibili sono utili alla soluzione del problema originale e quindi non vanno calcolate e memorizzate. Questa tecnica fonde l'approccio di memorizzazione della programmazione dinamica con l'approccio top-down di divide et impera.\\
Passi per utilizzare la memoization:
\begin{itemize}
	\item Creare la tabella $DP$ e inizializzarla con un valore speciale ($+/- \infty, -1, null$) per indicare che un certo sottoproblema non è stato ancora risolto 
	\item Ogni volta che si deve risolvere un sottoproblema, si controlla nella tabella se è già stato risolto precedentemente: in caso affermativo si usa il risultato della tabella, altrimenti si calcola il risultato e lo si memorizza
	\item Ogni sottoproblema viene calcolato una sola volta e memorizzato come nella versione bottom-up
\end{itemize}
\newpage
\subsubsection{Zaino (Knapsack)}
\textbf{Problema:} Il problema è lo stesso visto per la programmazione dinamica. \\
\textbf{Implementazione:}
\begin{lstlisting}[ caption= Knapsack versione $\mathcal{O}(nC)$ zaino con memoization]
int knapsack(int[] w, int[] p, int n, int C)
	int[][] DP = new int[1...n][1...n]
	for i = 1 to n do
		for c = 1 to C do
			DP[i][c] = -1
	return knapsackRec(w, p, n, C, DP )
	
int knapsackRec(int[] w, int[] p, int i, int c, int[][] DP)
	if c < 0 then
		return -$\infty$
	else if i $==$ 0 or c $==$ 0 then
		return 0
	else 
		if DP[i][c] < 0 then 
			int $not\_taken$ = knapsackRec(w, p, i - 1, c, DP)
			int $taken$ = knapsackRec(w, p, i - 1, c - w[i], DP) + p[i]
			DP[i][c] = max($not\_taken, taken$)
	return DP[i][c]
\end{lstlisting}
\begin{lstlisting}[ caption= Knapsack versione con memoization e dizionario]
int knapsack(int[] w, int[] p, int n, int C)
	DP = new Hash
	return knapsackRec(w, p, n, C, DP )
	
int knapsackRec(int[] w, int[] p, int i, int c, Hash DP)
	if c < 0 then
		return -$\infty$
	else if i $==$ 0 or c $==$ 0 then
		return 0
	else 
		if (i, c) $\in$ DP.keys() then 
			int $not\_taken$ = knapsackRec(w, p, i - 1, c, DP)
			int $taken$ = knapsackRec(w, p, i - 1, c - w[i], DP) + p[i]
			DP.insert((i, c), max($not\_taken, taken$))
	return DP.lookup((i, c))
\end{lstlisting}
\textbf{Complessità:} La complessità dell'algoritmo è $\mathcal{O}(nC)$, quindi non sembrerebbe esserci nessun vantaggio se non la semplicità di convertire codice ricorsivo in memoization. Utilizzando l'hash al posto di una matrice per DP non è necessario fare l'inizializzazione e il costo di esecuzione diventa $\mathcal{O}( min (2^{n}, nC))$.
\newpage
\subsubsection{Zaino (Knapsack) senza limiti}
\textbf{Problema:} Il problema è lo stesso visto nei casi precedenti con la modifica che non si pone limite al numero di volte che un oggetto può essere selezionato. Come modificare dunque la formula ricorsiva in questo caso? Potrebbe venirci in mente una soluzione basata sulla programmazione greedy ma per come è espresso il problema siamo certi del fatto che esista una soluzione basata su programmazione dinamica.

\begin{equation*}
  	DP[i][c] =\begin{cases}
    	0 & \text{$i = 0$ or $c = 0$}\\
    	-\infty & \text{$c < 0$}\\
    	max(DP[i \textcolor{red}{-1}][c-w[i]]+p[i], DP[i-1][c]) & \text{$altrimenti$}
  	\end{cases}
\end{equation*} \\
Se rimuoviamo il $-1$ che troviamo nell'equazione di ricorrenza vista nei casi precedenti, ricadiamo nel caso in cui ci chiediamo se ci conviene prendere lo stesso oggetto più volte, pur avendo una capacità minore, oppure se ci conviene non prendere l'oggetto e passare a un altro. \\
Al posto che modificare la formula precedente, a cui basterebbe come detto precedentemente rimuovere il $-1$, proviamo a pensare a una soluzione più efficiente a livello di spazio occupato in memoria. \\\\
Dato dunque uno zaino senza limiti di scelta di capacità $C$ e $n$ oggetti caratterizzati da un peso $w$ e da un porfitto $p$, definiamo $DP[c]$ come il massimo profitto che può essere ottenuto da tali oggetti in uno zaino di capacità $c \leq C$\\\\
Se pensiamo al fatto che possiamo prendere un numero arbitrario di volte un qualsiasi oggetto, pur rimanendo vincolati dalla capacità residua dello zaino, questo significa che con capacità restante $c$, ci converrà prendere l'oggetto con profitto massimo ($max(p[i])$) con $w[i] \leq c$.

\begin{equation*}
  	DP[c] =\begin{cases}
    	0 & \text{$c = 0$}\\
    	max_{w[i] \leq c}\{DP[c-w[i]]+p[i]\} & \text{$c>0$}
  	\end{cases}
\end{equation*}\\\\
\textbf{Implemetazioni}
\begin{lstlisting}[caption= Knapsack zaino senza limiti]
int knapsack(int[] w, int[] p, int n, int C)
	int[] DP = new int[0...C]
	for i = 0 to C do
		DP[i] = -1
	knapsackRec(w, p, n, C, DP)
	return DP[C]
	
int knapsackRec(int[] w, int[] p, int n, int c, int[] DP)
	if c $==$ 0 then
	  return 0
	if DP[c] < 0 then
	  DP[c] = 0
	  for i = 1 to n do
	    if w[i] $\leq$ c then
	  	   int val = knapsackRec(w, p, n, c - w[i], DP) + p[i]
	   	   DP[c] = max(DP[c], val)
	return DP[c]
\end{lstlisting}
Qual è la complessità della funzione $knapsack()$?\\
La funzione knapsack deve generare un vettore grande $C$ e, nel caso peggiore, dovrà riempire tutti i suoi elementi. Riempire un singolo elemento ha costo $\mathcal{O}(n)$ e quindi il costo complessivo della funzione è  $\mathcal{O}(nC)$.\\\\
Se utilizziamo questo tipo di approccio lo spazio occupato in memoria è pari a $\Theta(C)$ ma ricostruire la soluzione diventa più complesso in quanto è necessario l'utilizzo di un altro vettore che ci dica da dove venga il massimo.
\begin{equation*}
  	DP[c] =\begin{cases}
    	0 & \text{$c = 0$}\\
    	max_{w[i] \leq c}\{DP[c-w[i]]+p[i]\} & \text{$c>0$}
  	\end{cases}
\end{equation*}
\begin{lstlisting}[caption= Knapsack Ricostruzione Soluzione]
LIST knapsack(int[] w, int[] p, int n, int C)
	int[] DP = new int[0...C]
	int[] pos = new int[0...C]
	for i = 0 to C do
		DP[i] = -1
		pos[i] = -1
	knapsackRec(w, p, n, C, DP, pos)
	return solution(w, C, pos)
	
int knapsackRec(int[] w, int[] p, int n, int c, int[] DP)
	if c $==$ 0 then
	  return 0
	if DP[c] < 0 then
	  DP[c] = 0
	  for i = 1 to n do
	    if w[i] $\leq$ c then
	  	   int val = knapsackRec(w, p, n, c - w[i], DP, pos) + p[i]
	  	   if val $\geq$ DP[c] then
	   	     DP[c] = val
	   	     pos[c] = i
	return DP[c]
	
LIST solution(int[] w, int c, int[] pos)
	if c $==$ 0 or pos[c] < 0 then
		return List()
	else
		LIST L = solution(w, c - w[pos[c]], pos)
		L.insert(L.head(), pos[c])
		return L
\end{lstlisting}
Quello che viene restituito dalla funzione $solution()$ è una lista di indici dove i suoi elementi possono comparire più di una volta (multinsieme). Notiamo che se $c=0$ allora lo zaino è stato riempito perfettamente mentre per $pos[c]<0$ allora lo zaino non può essere riempito interamente (rimarrà della capacità residua ma nessun oggetto in grado di riempirlo perfettamente).
\newpage
\subsection{Altri esempi di programmazione dinamica} 
\subsubsection{Sottosequenza comune massimale}
\textbf{Definizione: Sottosequenza}\\
Una sequenza $P$ è una \textcolor{red}{sottosequenza} di $T$ se $P$ è ottenuto da $T$ rimuovendo uno o più dei suoi elementi.\\\\
\textbf{Definizione: Sottosequenza comune}\\
Una sequenza $X$ è una \textcolor{red}{sottosequenza comune} di due sequenze $T, U$ se è sottosequenza sia di $T$ che di $U$.\\
Scriveremo $X \in \mathcal{CS}(T, U)$\\\\
\textbf{Definizione: Sottosequenza comune massimale}\\
Una sequenza $X \in \mathcal{CS}(T, U)$ è una \textcolor{red}{sottosequenza comune massimale} di due sequenze $T, U$ se non esiste un'altra sottosequenza $Y \in \mathcal{CS}(T, U)$ tale che $Y$ sia più lunga di $X$  ($|Y| > |X|$).\\
Scriveremo $X \in \mathcal{LCS}(T, U)$\\\\
\textbf{Problema: $\mathcal{LCS}$}\\
Date due sequenze $T$ e $U$, trovare la più lunga sottosequenza comune tra le due.\\\\
Per poter descrivere la soluzione matematica ottima abbiamo ancora bisogno di un'altra definizione:\\
\textbf{Prefisso}: Data una sequenza $T$ composta da $t_{1}t_{2}...t_{n}$, $T(i)$ denota il \textcolor{red}{prefisso} dei primi $i$ caratteri cioè: $T(i) = t_{1}t_{2}...t_{i}$\\\\
\textbf{Analisi dei casi ricorsivi}
\begin{itemize}
	\item \textbf{Caso 1:}\\
Si considerino due prefissi $T(i)$ e $U(j)$ tali per cui il loro ultimo carattere coincide: $t_{i} = u_{j}$.\\
es: $T(i) = ALBERTO$, $U(j) = PIERO$.\\
\textbf{Soluzione}\\
$LCS(T(i), U(j))$ = $LCS(T(i-1), U(j-1))$ $\oplus$ $t_{i}$\\
nel caso dell'esempio mostrato sopra:\\
$LCS(ALBERTO, PIERO)$ = $LCS(ALBERT, PIER)$ $\oplus$ O
	\item \textbf{Caso 2:}\\
Si considerino due prefissi $T(i)$ e $U(j)$ tali per cui il loro ultimo carattere è differente: $t_{i} \neq u_{j}$.\\
es: $T(i) = ALBERT$, $U(j) = PIER$.\\
\textbf{Soluzione}\\
$LCS(T(i), U(j))$ = $longest(LCS(T(i-1), U(j)), LCS(T(i), U(j-1)))$\\
nel caso dell'esempio mostrato sopra:\\
$LCS(ALBERTO, PIERO)$ = $longest (LCS(ALBER, PIER), LCS(ALBERT, PIE))$\\
\end{itemize}
\textbf{Casi Base}\\
La più lunga sottosequenza tra $T(i)$ e $U(j)$ quando uno dei due è vuoto è $LCS(T(i), U(0))$ = $\emptyset$\\\\
\textbf{Formula Completa}\\
\begin{equation*}
  	LCS(T(i), U(j)) =\begin{cases}
    	\emptyset & \text{$i = 0$ or $j=0$}\\
    	LCS(T(i-1), U(j-1)) \oplus t_{i} & \text{$i>0$ and $j>0$ and $t_{i} = u_{j}$}\\
    	longest(LCS(T(i-1), U(j)), LCS(T(i), U(j-1))) & \text{$i>0$ and $j>0$ and $t_{i} \neq u_{j}$}
    	
  	\end{cases}
\end{equation*}
\textbf{Lunghezza della LCS}\\
Date due sequenze $T$ e $U$ di lunghezza $n$ e $m$, scrivere una formula ricorsiva $DP[i][j]$ che restituisca la \textcolor{red}{lunghezza} della LCS dei prefissi $T(i)$ e $U(j)$.

\begin{equation*}
  	DP[i][j] =\begin{cases}
    	0 & \text{$i = 0$ or $j=0$}\\
    	DP[i-1][j-1] + 1 & \text{$i>0$ and $j>0$ and $t_{i} = u_{j}$}\\
    	max \{DP[i-1][j], DP[i][j-1]\} & \text{$i>0$ and $j>0$ and $t_{i} \neq u_{j}$}
    	
  	\end{cases}
\end{equation*}
L'informazione relativa alla lunghezza della LCS del problema si troverà in $DP[n][m]$.\\\\
\textbf{Esempio funzionamento soluzione e struttura dati}\\
La tabella seguente mostra la struttura dati che sarà presente in memoria dopo aver eseguito l'algoritmo sulle stringhe ATBCBD e TACCBT. La freccia che punta verso il basso vuol dire che l'elemento è stato ricavato dall'elemento presente sulla stessa colonna della tabella, ma sulla riga precedente, la freccia che punta verso destra che l'elemento proviene dalla stessa riga ma dalla colonna precedente, mentre la freccia diagonale che l'elemento è stato calcolato a partire dall'elemento sulla riga e sulla colonna precedente. 

\begin{center}
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{ |c|c|c|c|c|c|c|c|c| } 
		\hline
			&j &0 &1 &2 &3 &4 &5 &6\\
		\hline
			i & & &A &T &B &C &B &D\\
		\hline
			0 & &0 &0 &0 &0 &0 &0 &0\\
		\hline
			1 &T &0 & $\downarrow$ 0 & $\searrow$ 1 & $\rightarrow$ 1 & $\rightarrow$ 1 & $\rightarrow$ 1 & $\rightarrow$ 1\\
		\hline
			2 &A &0 & $\searrow$ 1 & $\downarrow$ 1 & $\downarrow$ 1 & $\downarrow$ 1 & $\downarrow$ 1 & $\downarrow$ 1\\
		\hline
			3 &C &0 & $\downarrow$ 1 & $\downarrow$ 1 & $\downarrow$ 1 & $\searrow$ 2 & $\rightarrow$ 2 & $\rightarrow$ 2\\
		\hline
			4 &C &0 & $\downarrow$ 1 & $\downarrow$ 1 & $\downarrow$ 1 & $\searrow$ 2 & $\downarrow$ 2 & $\rightarrow$ 2\\
		\hline
			5 &B &0 & $\downarrow$ 1 & $\downarrow$ 1 & $\searrow$ 2 & $\downarrow$ 2 & $\searrow$ 3 & $\rightarrow$ 3\\
		\hline
			6 &T &0 & $\downarrow$ 1 & $\searrow$ 2 & $\downarrow$ 2 & $\downarrow$ 2 & $\downarrow$ 3 & $\downarrow$ 3\\
			\hline
	\end{tabular}
\end{center}
Il risultato dell'esempio lo troviamo nella tabella in posizione [6,6] e vale 3. L'insieme delle soluzioni (cioè le lettere appartenenti alla sottosequenza massima) possono essere ricavate seguendo le frecce nella presenti nella struttura dati.\\\\
\textbf{Implementazione ricorrenza}
\begin{lstlisting}[caption= Lunghezza LCS]
int lcs(int[] T, int[] U, int n, int m)
	int[][] DP = new int[0...n][0...m]
	for i = 0 to n do
		for j = 0 to m do
			if i = 0 or j = 0 then
				DP[i][j] = 0
	for i = 1 to n do
		for j = 1 to m do
			if T[i] $==$ U[j] then
				DP[i][j] = DP[i-1][j-1] + 1
			else
				DP[i][j] = max(DP[i-1][j], DP[i][j-1])
	return DP[n][m]
\end{lstlisting}
\newpage
\begin{flushleft}
Nel caso in cui si voglia invece restituire la sottosequenza comune è invece necessario usare un algoritmo di questo tipo:
\end{flushleft}
\begin{lstlisting}[caption=Ricostruire LCS]
LIST lcs(int[] T, int[] U, int n, int m)
	...
	return subsequence(DP, T, U, n, m)
	
LIST subsequence(int[][] DP, ITEM[] T, ITEM[] U, int i, int j)
	if i $==$ 0 or j $==$ 0 then
		return List()
	if T[i] $==$ U[j] then
		S = subsequence(DP, T, U, i-1, j-1)
		S.insert(S.head(), T[i])
		return S
	else
		if DP[i-1][j] > DP[i][j-1] then
			return subsequence(DP, T, U, i-1, j)
		else
			return subsequence(DP, T, U, i, j-1)
\end{lstlisting}
La complessità computazionale di subsequence è al massimo $T(n) = \mathcal{O}(m+n)$ che  corrisponde al numero massimo di controlli che verranno eseguiti per ricostituire la soluzione, mentre il costo per creare e riempire la matrice è pari a $T(n) = \mathcal{O}(mn)$. In totale il costo di LCS è pari a $T(n) = \mathcal{O}(mn)$.

\subsubsection{String matching approssimato}
\textbf{Definizione:} Un'occorrenza \textcolor{red}{$k-approssimata$} di $P$ in $T$, dove: 
\begin{itemize}
	\item $P = p_{1}...p_{m}$ è una stringa detta pattern
	\item $T = t_{1}...t_{n}$ è una stringa detta testo, con $m \leq n$,
\end{itemize}
è una copia di $P$ in $T$ in cui sono ammessi $k$ "errori" (o differenze) tra caratteri di $P$ e caratteri di $T$, del seguente tipo:
\begin{itemize}
	\item i corrispondenti caratteri in $P$, $T$ sono diversi (sostituzione) 
	\item un carattere in $P$ non è incluso in $T$ (inserimento)
	\item un carattere in $T$ non è incluso in $P$ (cancellazione)
\end{itemize}
\textbf{Problema:} Trovare un'occorrenza \emph{k-approssimata} di $P$ in $T$ con $k$ minimo (0 $\leq$ k $\leq$ m).\\\\
\textbf{Sottostruttura ottima e formula ricorsiva}
Sia $DP[0...m][0...n]$ una tabella di programmazione dinamica tale che $DP[i][j]$ sia il minimo valore $k$ per cui esiste un’occorrenza k-approssimata di $P(i)$ in $T(j)$ che termina nella posizione $j$.
\begin{equation*}
  	DP[i][j] =\begin{cases}
    	0 & \text{$i = 0$}\\
    	i & \text{$i = 0$}\\
    	min(DP[i-1][j-1] + d , DP[i-1][j] + 1, DP[i][j-1] + 1)  & \text{$altrimenti$}   	
  	\end{cases}
\end{equation*}
\begin{center}
dove $d = iif(P[i] == T[j]$, 0 , 1).
\end{center}
\newpage
\begin{flushleft}
La formula tratta i vari casi: se $P[i]=T[j]$ avanza su entrambi i caratteri, se $P[i] \neq T[j]$ avanza aggiungi 1 e trova la soluzione minima tra avanzare sul pattern (inserimento), avanzare sul testo (cancellazione) e avanzare su entrambi i caratteri (sostituzione).
\end{flushleft}
\textbf{Implementazione:}
\begin{lstlisting}[caption=String matching approssimato]
int stringMatching(ITEM[] P, ITEM[] T, int m, int n)
	int[][] DP = new int[0...m][0...n]
	for j = 0 to n do DP[0][j] = 0  % Caso base: i = 0
	for i = 1 to m do DP[i][0] = i  % Caso base: j = 0
	for i = 1 to m do        	% Caso generale 
		for j = 1 to n do
			DP[i][j] = min( DP[i-1][j-1] + iif(P[i] $==$ T[j], 0, 1),	
					DP[i-1][j] + 1,
					DP[i][j-1] + 1)
	% Calcola minimo ultima riga
	int pos = 0 
	for j = 1 to n do
		if DP[m][j] < DP[m][pos] then
			pos = j
	return pos
\end{lstlisting}
\subsubsection{Prodotto di catena di matrici}
\textbf{Problema:} Data una sequenza di n matrici $A_1, A_2, A_3, ..., A_n$, compatibili due a due al prodotto, vogliamo calcolare il loro prodotto.\\
Il prodotto di matrici: non è commutativo, è \textcolor{red}{associativo}: ($A_1 \cdot A_2) \cdot A_3 = A_1 \cdot (A_2 \cdot A_3$) e si basa sulla moltiplicazione scalare come operazione elementare. Vogliamo calcolare il prodotto delle $n$ matrici impiegando il più basso numero possibile di moltiplicazioni scalari.\\\\
\textbf{Definizioni:} Una \emph{parentesizzazione} $P_{i,j}$ del prodotto $A_i \cdot A_{i+1}\cdot ... \cdot A_j$ consiste:
\begin{itemize}
	\item nella matrice $A_i$, se $i = j$;
	\item nel prodotto di due parentesizzazioni ($P_{i,k} \cdot P_{k+1,j}$), altrimenti.
\end{itemize}
Una \textbf{Parentesizzazione ottima} è la parentesizzazione che richiede il minor numero di moltiplicazioni scalari per essere completata, fra tutte le parentesizzazioni possibili.\\
In ogni parentesizzazione ottima esiste un ultimo prodotto cioè esiste un indice k tale che $P[i...j] = P[i...k] \cdot P[k+1...j]$ dove $P[i...j]$ rappresenta una parentesizzazione per il prodotto $A_i \cdot A_{i+1} \cdot ... \cdot A_j$.\\
Definiamo inoltre $c_{i-1}$ il numero di righe della matrice $A_i$ e $c_{i}$  il numero di colonne della matrice $A_i$.\\\\
\textbf{Sottostruttura ottima e formula ricorsiva:} Se $P[i...j] = P[i...k]P[k+1...j]$ è una parentesizzazione ottima del prodotto $A[i...j]$, allora:
\begin{itemize}
	\item $P[i...k]$ è parentesizzazione ottima del prodotto $A[i...k]$
	\item $P[k+1...j]$ è parentesizzazione ottima del prodotto $A[k+1...j]$
\end{itemize}
Non conosciamo quanto vale $k$, ma possiamo provare per tutti i valori possibili fra $i$ e $j-1$.
Definizione ricorsiva:
\begin{equation*}
  	DP[i][j] =\begin{cases}
    	0 & \text{$i = j$}\\
    	min_{i \leq k \leq j}(DP[i][k]+DP[k+1][j]+c_{i-1} \cdot c_{k} \cdot c_{j})  & \text{$i < j$}  
  	\end{cases}
\end{equation*}
\newpage
\begin{lstlisting}[caption= Calcolo prodotto di matrici e stampa parentesizzazione ottima usando matrice last]
%ricostruzione della soluzione (stampa prodotto)
printPar(int[][] last , int i, int j)
	if i $==$ j then
		print "A["; print i; print "]"
	else
		print "(";
		stampaPar(last, i, last[i][j]);
		print "$\cdot$";
		printPar(last, last[i][j] +1, j);
		print ")"

%calcolo prodotto matrici usando last 
int[][] multiply(matrix[] A, int[][] last, int i, int j)
	if i $==$ j then
		return A[i]
	else
		int[][] X = multiply(A, last, i, last[i][j])
		int[][] Y = multiply(A, last, last[i][j] + 1, j)
		%matrix-multiplication calcola il prodotto tra le  matrici X e Y
		return matrix-multiplication(X,Y)
\end{lstlisting}
\noindent
L'implementazione usa le matrici $DP$ e $last$ di dimensione $n \times n$ tali che:
\begin{itemize}
	\item $DP[i][j]$ contiene il numero di moltiplicazioni scalari necessarie per moltiplicare le matrici $A[i...j]$ 
	\item $last [i][j]$ contiene il valore $k$ dell'ultimo prodotto che minimizza il costo per il sottoproblema
\end{itemize}
\begin{lstlisting}[caption= Calcolo parentesizzazione ottima]
%calcolo della soluzione ottima
computePar(int[] c, int n)
	int[][] DP = new int[1...n][1... n]
	int[][] last = new int[1...n][1...n]
	% Fill main diagonal
	for i = 1 to n do 
		DP[i][i] = 0
	% h: diagonal index
	% i: row
	% j: column
	for h = 2 to n do
		for i = 1 to n - h + 1 do 
			int j = i + h - 1 
			DP[i][j] = +1
			% k: last product
			for k = i to j - 1 do 
				int temp = DP[i][k] + DP[k+1][j] + 
				           c[i-1]$ \cdot$ c[k] $\cdot$ c[j]
				if temp < DP[i][j] then
					DP[i][j] = temp
					last [i][j] = k
	return DP[1][n]
\end{lstlisting}
\textbf{Costo computazionale:} Il costo di $computePar()$ è pari a $\mathcal{O}(n^{3})$.
\newpage
\subsubsection{Insieme indipendente di intervalli pesati}
\textbf{Definizioni e input:} Siano dati n intervalli distinti $[a_1, b_1[, ..., [a_n,b_n[$ della retta reale, aperti a destra, dove all'intervallo $i$ è associato un profitto $w_{i}$, $1\leq i \leq n$. Due intervalli $i$ e $j$ sono \emph{disgiunti} se $b_j \leq a_i$ oppure $b_i \leq a_j.$\\\\
\textbf{Problema:} Trovare un \textcolor{red}{insieme indipendente di peso massimo}, ovvero un sottoinsieme di intervalli disgiunti tra loro tale che la somma dei loro profitti sia la più grande possibile.\\\\
\textbf{Soluzione:} Per usare la programmazione dinamica, è necessario effettuare una pre-elaborazione: ordinare gli intervalli per estremi finali crescenti cioè $b_1 \leq b_2 \leq ... \leq b_n$. \\
Una seconda possibile pre-elaborazione consiste nel pre-calcolare il predecessore $pred_{i} = j$ di $i$, dove: 
\begin{itemize}
	\item $j < i$ è il massimo indice tale che $b_j \leq a_i$
	\item se non esiste tale indice, $pred_{i} = 0$.
\end{itemize}
Definiamo la ricorrenza:
\begin{equation*}
  	DP[i] =\begin{cases}
    	0 & \text{$i = 0$}\\
    	max(DP[i-1], DP[pred_{i}] + w_{i})  & \text{$i > 0$}   	
  	\end{cases}
\end{equation*}
dove $DP[i]$ contiene il profitto massimo ottenibile con i primi i intervalli.\\\\
\newpage
\noindent
\textbf{Implementazione:}
\begin{lstlisting}[caption= Insieme indipendente di intervalli pesati]
SET maxinterval(int[] a, int[] b, int[]w, int n)
	{ordina gli intervalli per estremi di fine crescenti}
	int[] pred = computePredecessor(a, b, n)
	int[] DP = new int[0...n]
	DP[0] = 0
	for i = 1 to n do
		DP[i] = max(DP[i-1], w[i]+DP[pred[i]])
	i = n
	SET S = Set()
	while i > 0 do
		if DP[i-1] > w[i] + DP[pred[i]] then
			i = i - 1
		else
			S.insert(i)
			i = pred[i]
	return S

	
int[] computePredecessor(int[] a, int[] b, int n)
	int[] pred = new int[0...n]
	pred[0] = 0
	for i = 1 to n do
		j = i-1
		while j > 0 and b[j] > a[i] do
			j = j-1
		pred[i] = j
	return pred
\end{lstlisting}
\textbf{Costo computazionale:} Il costo per calcolare i predecessori mostrato nel codice è pari a $\mathcal{O}(n^{2})$, ma si può fare meglio di così ed arrivare ad un costo $\mathcal{O}(n \log n)$.
In totale il costo di $maxinterval()$ è pari a $\mathcal{O}(n \log n)$ in quanto il calcolo dei predecessori vale $\mathcal{O}(n \log n)$, l'ordinamento vale $\mathcal{O}(n \log n)$, il riempimento di DP vale $\mathcal{O}(n)$  e la ricostruzione della soluzione costa $\mathcal{O}(n)$.
\subsection{Schema risoluzione problema}
\textbf{Fasi risoluzione problema con programmazione dinamica/memoization:}\
\begin{itemize}
	\item Caratterizzare la struttura di una soluzione ottima
	\item Dimostrare che la soluzione gode di sottostruttura ottima
	\item Definire ricorsivamente il valore di una soluzione ottima
	\item Calcolare il valore di una soluzione ottima "bottom-up" (programmazione dinamica) / "top-down" (memoization)
	\item Ricostruzione di una soluzione ottima
\end{itemize}
\newpage
\end{document}