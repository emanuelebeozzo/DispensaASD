\documentclass[../cheatSheetAlgoritmi.tex]{subfiles}
\begin{document}

\section{Programmazione dinamica e memoization}
\subsection{Programmazione dinamica}
\textbf{Introduzione} Tecnica classica di risoluzione dei problemi che consiste nello spezzare il problema ricorsivamente in sottoproblemi. A differenza della tecnica del divide-et-impera, ogni sotto problema viene risolto solo una volta e la sua soluzione viene memorizzata in una tabella. Nel caso bisognasse risolvere nuovamente il sottoproblema, si ottiene la soluzione facendo un semplice accesso alla tabella senza effettuare di nuovo il calcolo. La tabella ha un costo di lookup pari a  $\mathcal{O}$(1). 

\subsubsection{Domino}
\textbf{Problema:} Il gioco del domino è basato su tessere di dimensione $2\times1$. Scrivere un algoritmo efficiente che prenda in input un intero n e restituisca il numero di possibili disposizioni di n tessere in un rettangolo $2\times n$. \\\\
\textbf{Soluzione:} Iniziamo a considerare alcuni casi per definire una soluzione. Con n=0 abbiamo solo una disposizione possibile (nessuna tessera), con n=1 abbiamo solo una disposizione possibile (tessera messa in verticale). L'ultima tessera può essere disposta in due modi: se la posiziono in verticale devo risolvere il problema con dimensione n-1, mentre se la metto in orizzontale devo per forza mettere 2 tessere e risolvere il problema di dimensione n-2. In generale la soluzione ha la seguente forma: 

\begin{equation*}
  	DP[n] =\begin{cases}
    	1 & \text{$n \leq 1$}\\
    	DP[n-2] + DP[n-1] & \text{$n > 1$}
  	\end{cases}
\end{equation*}\\\\
Notiamo che il risultato è la sequenza di Fibonacci: 1, 1, 2, 3, 5, 8, ... \
Proponiamo 3 soluzioni al problema:
\begin{itemize}
	\item domino1(): soluzione ricorsiva che non fa uso della programmazione dinamica e risolve più volte gli stessi sottoproblemi
	\item domino2(): soluzione con programmazione dinamica che memorizza il risultato in una tabella DP. L'approccio è bottom-up cioè si parte risolvendo i casi base e risalendo si risolvono problemi sempre più grandi. La tabella DP in questo caso memorizza il risultato per ogni sottoproblema con dimensione tra 0 e n.
	\item domino3(): la soluzione proposta è uguale alla precedente con la differenza che l'uso di memoria è ridotto salvando solo la soluzione degli ultimi 3 sottoproblemi. 
\end{itemize}
\newpage
\noindent
\textbf{Implementazione:}
\begin{lstlisting}[ caption= Domino/Fibonacci versione $\mathcal{O}(2^n)$]
int domino1(int n)
	if n $\leq$ 1 then
		return 1
	else
		return domino1(n - 1) + domino1(n - 2)
\end{lstlisting}

\begin{lstlisting}[ caption= Domino/Fibonacci versione $\mathcal{O}(n^2)$ in tempo e spazio]
int domino2(int n)
	DP = new int[0...n]
	DP[0] = DP[1] = 1
	for i = 2 to n do
		DP[i] = DP[i - 1] + DP[i - 2]
	return DP[n]
\end{lstlisting}

\begin{lstlisting}[ caption= Domino/Fibonacci versione $\mathcal{O}(n^2)$ in tempo $\mathcal{O}(n)$ e spazio]
int domino3(int n)
	int $DP_0$ = 1
	int $DP_1$ = 1
	int $DP_2$ = 1
	for i = 2 to n do
		$DP_0$ = $DP_1$
		$DP_1$ = $DP_2$
		$DP_2$ = $DP_0$ + $DP_1$
	return $DP_2$
\end{lstlisting}
\textbf{Complessità:} Per calcolare la complessità dobbiamo usare il modello di costo logaritmico che tiene consto lo spazio necessario per salvare un numero della sequenza di Fibonacci ($\Theta(n)$) e il costo per sommare due numeri consecutivi della sequenza ($\Theta(n)$). 
Il costo per le varie versioni è il seguente: 
\begin{center}
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{ |c|c|c| } 
		\hline
			Funzione & Complessità (Tempo) & Complessità (Spazio)\\ 
		\hline
			domino1() & $\mathcal{O}$(n$2^{n}$) &  $\mathcal{O}$($n^{2}$)\\ 
		\hline
			domino2() &  $\mathcal{O}$($n^{2}$) &  $\mathcal{O}$($n^{2}$) \\
		\hline
			domino3() &  $\mathcal{O}$($n^{2}$) &  $\mathcal{O}$(n) \\
		\hline
	\end{tabular}
\end{center} \


\subsubsection{Hateville}
\textbf{Problema:} Hateville è un villaggio particolare, composto da n case, numerate da 1 a n lungo una singola strada. Ad Hateville ognuno odia i propri vicini della porta accanto, da entrambi i lati. Quindi, il vicino i odia i vicini i-1 e i+1 (se esistenti).
Hateville vuole organizzare una sagra e vi ha affidato il compito di
raccogliere i fondi. Ogni abitante i ha intenzione di donare una quantità D[i], ma non intende partecipare ad una raccolta fondi a cui partecipano uno o entrambi i propri vicini. Scrivere un algoritmo che restituisca il sottoinsieme di indici S  $\subseteq$ $\{$1, ..., n $\}$ tale per cui la donazione totale T = $\sum\limits_{i \in S} {D[i]}$ è massimale. \\\\
\textbf{Soluzione:} Definiamo il problema in questi termini: 
\begin{itemize}
	\item Sia HV(i) uno dei possibili insiemi di indici da selezionare per ottenere una donazione ottimale dalle prime i case di Hateville,
numerate 1...n
	\item HV(n) è la soluzione del problema originale
	\item Se non accetto la donazione i-esima: HV(i) = HV(i-1)
	\item Se accetto la donazione i-esima: HV(i) = {i} $\cup$ HV(i-2)
	\item Per decidere se accettare una donazione i: HV(i) = highest(HV(i -1),  $\{$i$\}$ $\cup$ HV(i-2))
	\item Casi base: HV(0) = $\emptyset$ e HV(1) = $\{$1$\}$ \\
\end{itemize} 
Mettendo tutto insieme otteniamo:
\begin{equation*}
  	HV(i) =\begin{cases}
    	\emptyset & \text{$i = 0$}\\
    	\{1\} & \text{$i = 1$}\\
    	highest(HV(i -1), \{i\} \cup HV(i-2)) & \text{$i \ge 2$}
  	\end{cases}
\end{equation*} \\
Per riuscire a calcolare l'insieme delle soluzioni dobbiamo prima calcolare il valore della soluzione massimale usando la programmazione dinamica e poi ricostruiamo la soluzione partendo da questo valore. La ricorrenza per trovare il valore massimale con la programmazione dinamica è la seguente:

\begin{equation*}
  	DP[i] =\begin{cases}
    	0 & \text{$i = 0$}\\
    	D[1] & \text{$i = 1$}\\
    	max(DP[i -1], DP[i-2]+D[i]) & \text{$i \ge 2$}
  	\end{cases}
\end{equation*} \\\\
\textbf{Implementazione:}
\begin{lstlisting}[ caption= Hateville versione $\mathcal{O}(n)$ senza calcolo della soluzione]
int hateville(int[] D, int n)
	int[] DP = new int[0...n]
	DP[0] = 0
	DP[1] = D[1+
	for i = 2 to n do
		DP[i] = max(DP[i - 1], DP[i - 2] + D[i])
	return DP[n]
\end{lstlisting}

\begin{lstlisting}[ caption= Soluzione di Hateville versione $\mathcal{O}(n)$]
SET solution(int[] DP, nit[] D, int i)
	if i == 0 then
		return $\emptyset$
	else if i == 1 then
		return {1}
	else if DP[i] == DP[ i - 1]  then
		return solution(DP, D, i  - 1)
	else
		SET sol = solution(DP, D, i - 2)
		sol.insert(i)
		return sol
\end{lstlisting}

\begin{lstlisting}[ caption= Hateville versione $\mathcal{O}(n)$ completa]
int hateville(int[] D, int n)
	int[] DP = new int[0...n]
	DP[0] = 0
	DP[1] = D[1+
	for i = 2 to n do
		DP[i] = max(DP[i - 1], DP[i - 2] + D[i])
	print DP[n]
	return solution(DP, D, n)
\end{lstlisting}
\textbf{Complessità:}  
\begin{itemize}
	\item Complessità solution(): $\Theta(n)$
	\item Complessità hateville() (sia per tempo che per spazio): $\Theta(n)$
\end{itemize} \

\subsubsection{Zaino (Knapsack)}
\textbf{Problema:} Dato un insieme di oggetti, ognuno caratterizzato da un peso e un
profitto, e uno "zaino" con un limite di capacità, individuare un
sottoinsieme di oggetti: 
\begin{itemize}
	\item il cui peso sia inferiore alla capacità dello zaino;
	\item il valore totale degli oggetti sia massimale, i.e. più alto o uguale al valore di qualunque altro sottoinsieme di oggetti
\end{itemize} \
Siano dati in input: 
\begin{itemize}
	\item Vettore w, dove w[i] è il peso (weight) dell’oggetto i-esimo
	\item Vettore p, dove p[i] è il profitto (profit) dell’oggetto i-esimo
	\item La capacità C dello zaino
\end{itemize} \
L'output deve essere un insieme S  $\subseteq$ $\{$1, ..., n $\}$ tale che:
\begin{itemize}
	\item Il volume totale deve essere minore o uguale alla capacità 
	\item Il profitto totale deve essere massimizzato\\
\end{itemize} 
\textbf{Soluzione:} Dato uno zaino di capacità C e n oggetti caratterizzati da peso w e profitto p, definiamo DP[i][c] come il massimo profitto che puòessere ottenuto dai primi i $\leq$ n oggetti contenuti in uno zaino di
capacità c $\leq$ C. Il massimo profitto ottenibile per il problema originale è rappresentato da DP[n][C]. \ Considerando i vari casi (prendere o meno l'ultimo elemento e i vari casi base) otteniamo la seguente formula ricorsiva: 

\begin{equation*}
  	DP[i] =\begin{cases}
    	0 & \text{$i = 0$  or  $c = 0$}\\
    	-\infty & \text{$c < 0$}\\
    	max(DP[i -1][c-w[i]]+p[i], DP[i-1][c]) & \text{$altrimenti$}
  	\end{cases}
\end{equation*} \\\\
\newpage
\noindent
\textbf{Implementazione:}
\begin{lstlisting}[ caption= Knapsack versione $\mathcal{O}(nC)$ con programmazione dinamica]
int knapsack(int[] w, int[] p, int n, int C)
	int[][] DP = new int[0...n][0...n]
	for i = 0 to n do
		DP[i][0] = 0
	for c = 0 to n do
		DP[0][c] = 0
	for i = 1 to n do
		for c = 1 to C do
			if w[i] $\leq$ c then
				DP[i][c] = max(DP[i - 1][c - w[i]] + p[i], DP[i - 1][c])
			else
					DP[i][c] = DP[i - 1][c]
	return DP[n][C]
\end{lstlisting}
\textbf{Complessità:} La complessità dell'algoritmo è $\mathcal{O}$(nC), ma se consideriamo che sono necessari k = log C bit per rappresentare C, la complessità diventa pseudo-polinomiale e vale T(n) = $\mathcal{O}$(n$2^{k}$).
La versione ricorsiva che non fa uso della ricorsione costa $\mathcal{O}$($2^{n}$). Questo è un problema NP completo. 
\\

\subsection{Memoization}
\textbf{Introduzione} Non tutte le soluzioni dei sottoproblemi possibili sono utili alla soluzione del problema originale e quindi non vanno calcolate e memorizzate. Questa tecnica fonde l'approccio di memorizzazione della programmazione dinamica con l'approccio top-down di divide et impera. Passi per utilizzare la memoization:
\begin{itemize}
	\item Creare la tabella DP e inizializzarla con un valore speciale (+/- infinito, -1, null) per indicare che un certo sottoproblema non è stato ancora risolto 
	\item Ogni volta che si deve risolvere un sottoproblema, si controlla nella tabella se è già stato risolto precedentemente: in caso affermativo si usa il risultato della tabella, altrimenti si calcola il risultato e lo si memorizza
	\item Ogni sottoproblema viene calcolato una sola volta e memorizzato come nella versione bottom-up
\end{itemize} \ 


\subsubsection{Zaino (Knapsack)}
\textbf{Problema:} Il problema è lo stesso visto per la programmazione dinamica. \\
\textbf{Implementazione:}
\begin{lstlisting}[ caption= Knapsack versione $\mathcal{O}(nC)$ zaino con memoization]
int knapsack(int[] w, int[] p, int n, int C)
	int[][] DP = new int[1...n][1...n]
	for i = 1 to n do
		for c = 1 to C do
			DP[i][c] = -1
	return knapsackRec(w, p, n, C, DP )
	
int knapsackRec(int[] w, int[] p, int i, int c, int[][] DP)
	if c < 0 then
		return -$\infty$
	else if i == 0 or c == 0 then
		return 0
	else 
		if DP[i][c] < 0 then 
			int not_taken = knapsackRec(w, p, i - 1, c, DP)
			int taken = knapsackRec(w, p, i - 1, c - w[i], DP) + p[i]
			DP[i][c] = max(not_taken, taken)
	return DP[i][c]
\end{lstlisting}


\begin{lstlisting}[ caption= Knapsack versione con memoization e dizionario]
int knapsack(int[] w, int[] p, int n, int C)
	DP = new Hash
	return knapsackRec(w, p, n, C, DP )
	
int knapsackRec(int[] w, int[] p, int i, int c, Hash DP)
	if c < 0 then
		return -$\infty$
	else if i == 0 or c == 0 then
		return 0
	else 
		if (i, c) $\in$ DP.keys() then 
			int not_taken = knapsackRec(w, p, i - 1, c, DP)
			int taken = knapsackRec(w, p, i - 1, c - w[i], DP) + p[i]
			DP.insert((i, c), max(not_taken, taken))
	return DP.lookup((i, c))
\end{lstlisting}
\textbf{Complessità:} La complessità dell'algoritmo è $\mathcal{O}$(nC), quindi non sembrerebbe esserci nessun vantaggio se non la semplicità di convertire codice ricorsivo in memoization. Utilizzando l'hash al posto di una matrice per DP non è necessario fare l'inizializzazione e il costo di esecuzione diventa $\mathcal{O}$( min ( $2^{n}$ , nC)).\


\subsubsection{Zaino (Knapsack) senza limiti}
\textbf{Problema:} Il problema è lo stesso visto nei casi precedenti con la modifica che non si pone limite al numero di volte che un oggetto può essere selezionato. Come modificare dunque la formula ricorsiva in questo caso? Potrebbe venirci in mente una soluzione basata sulla programmazione greedy ma per come è espresso il problema siamo certi del fatto che esista una soluzione basata su programmazione dinamica.

\begin{equation*}
  	DP[i][c] =\begin{cases}
    	0 & \text{$i = 0$ or $c = 0$}\\
    	-\infty & \text{$c < 0$}\\
    	max(DP[i \textcolor{red}{-1}][c-w[i]]+p[i], DP[i-1][c]) & \text{$altrimenti$}
  	\end{cases}
\end{equation*} \\
Se rimuoviamo il $-1$ che troviamo nell'equazione di ricorrenza vista nei casi precedenti, ricadiamo nel caso in cui ci chiediamo se ci conviene prendere lo stesso oggetto più volte, pur avendo una capacità minore, oppure se ci conviene non prendere l'oggetto e passare a un altro. \\
Al posto che modificare la formula precedente, a cui basterebbe come detto precedentemente rimuovere il $-1$, proviamo a pensare a una soluzione più efficiente a livello di spazio occupato in memoria. \\\\
Dato dunque uno zaino senza limiti di scelta di capacità $C$ e $n$ oggetti caratterizzati da un peso $w$ e da un porfitto $p$, definiamo $DP[c]$ come il massimo profitto che può essere ottenuto da tali oggetti in uno zaino di capacità $c \leq C$\\\\
Se pensiamo al fatto che possiamo prendere un numero arbitrario di volte un qualsiasi oggetto, pur rimanendo vincolati dalla capacità residua dello zaino, questo significa che con capacità restante $c$, ci converrà prendere l'oggetto con profitto massimo ($max(p[i])$) con $w[i] \leq c$.

\begin{equation*}
  	DP[i][c] =\begin{cases}
    	0 & \text{$c = 0$}\\
    	max_{w[i] \leq c}\{DP[c-w[i]]+p[i]\} & \text{$c>0$}
  	\end{cases}
\end{equation*}\\\\
\textbf{Implemetazioni}
\begin{lstlisting}[caption= Knapsack zaino senza limiti]
int knapsack(int[] w, int[] p, int n, int C)
	int[] DP = new int[0...C]
	for i = 0 to C do
		DP[i] = -1
	knapsackRec(w, p, n, C, DP)
	return DP[C]
	
int knapsackRec(int[] w, int[] p, int n, int c, int[] DP)
	if c == 0 then
	  return 0
	if DP[c] < 0 then
	  DP[c] = 0
	  for i = 1 to n do
	    if w[i] $\leq$ c then
	  	   int val = knapsackRec(w, p, n, c - w[i], DP) + p[i]
	   	   DP[c] = max(DP[c], val)
	return DP[c]
\end{lstlisting}
Qual è la complessità della funzione knapsack()?\\
La funzione knapsack deve generare un vettore grande $C$ e, nel caso peggiore, dovrà riempire tutti i suoi elementi. Riempire un singolo elemento ha costo $\mathcal{O}(n)$ e quindi il costo complessivo della funzione è  $\mathcal{O}(Cn)$.\\\\
Se utilizziamo questo tipo di approccio lo spazio occupato in memoria è pari a $\Theta(C)$ ma ricostruire la soluzione diventa più complesso in quanto è necessario l'utilizzo di un altro vettore che ci dica da dove venga il massimo.

\begin{equation*}
  	DP[i][c] =\begin{cases}
    	0 & \text{$c = 0$}\\
    	max_{w[i] \leq c}\{DP[c-w[i]]+p[i]\} & \text{$c>0$}
  	\end{cases}
\end{equation*}
\newpage
\begin{lstlisting}[caption= Knapsack Ricostruzione Soluzione]
LIST knapsack(int[] w, int[] p, int n, int C)
	int[] DP = new int[0...C]
	int[] pos = new int[0...C]
	for i = 0 to C do
		DP[i] = -1
		pos[i] = -1
	knapsackRec(w, p, n, C, DP, pos)
	return solution(w, C, pos)
	
int knapsackRec(int[] w, int[] p, int n, int c, int[] DP)
	if c == 0 then
	  return 0
	if DP[c] < 0 then
	  DP[c] = 0
	  for i = 1 to n do
	    if w[i] $\leq$ c then
	  	   int val = knapsackRec(w, p, n, c - w[i], DP, pos) + p[i]
	  	   if val $\geq$ DP[c] then
	   	     DP[c] = val
	   	     pos[c] = i
	return DP[c]
	
LIST solution(int[] w, int c, int[] pos)
	if c==0 or pos[c] < 0 then
		return List()
	else
		LIST L = solution(w, c - w[pos[c]], pos)
		L.insert(L.head(), pos[c])
		return L
\end{lstlisting}
Quello che viene restituito dalla funzione solution() è una lista di indici dove i suoi elementi possono comparire più di una volta (multinsieme). Notiamo che se $c=0$ allora lo zaino è stato riempito perfettamente mentre per $pos[c]<0$ allora lo zaino non può essere riempito interamente (rimarrà della capacità residua ma nessun oggetto in grado di riempierlo perfettamente).
\\

\subsection{Esempio reale: Sottosequenza comune massimale}
\textbf{Definizione: Sottosequenza}\\
Una sequenza $P$ è una \textcolor{red}{sottosequenza} di $T$ se $P$ è ottenuto da $T$ rimuovendo uno o più dei suoi elementi.\\\\
\textbf{Definizione: Sottosequenza comune}\\
Una sequenza $X$ è una \textcolor{red}{sottosequenza comune} di due sequenze $T, U$ se è sottosequenza sia di $T$ che di $U$.\\
Scriveremo $X \in \mathcal{CS}(T, U)$\\\\
\textbf{Definizione: Sottosequenza comune}\\
Una sequenza $X \in \mathcal{CS}(T, U)$ è una \textcolor{red}{sottosequenza comune massimale} di due sequenze $T, U$ se non esiste un'altra sottosequenza $Y \in \mathcal{CS}(T, U)$ tale che $Y$ sia più lunga di $X$  ($|Y| > |X|$).\\
Scriveremo $X \in \mathcal{LCS}(T, U)$\\\\
\textbf{Problema: $\mathcal{LCS}$}\\
Date due sequenze $T$ e $U$, trovare la più lunga sottosequenza comune tra le due.\\\\
Per poter descrivere la soluzione matematica ottima abbiamo ancora bisogno di un'altra definizione:\\
\textbf{Prefisso}: Data una sequenza $T$ composta da $t_{1}t_{2}...t_{n}$, $T(i)$ denota il \textcolor{red}{prefisso} dei primi $i$ caratteri cioè: $T(i) = t_{1}t_{2}...t_{i}$\\\\
\textbf{Analisi dei casi ricorsivi}
\begin{itemize}
	\item \textbf{Caso 1:}\\
Si considerino due prefissi $T(i)$ e $U(j)$ tali per cui il loro ultimo carattere coincide: $t_{i} = u_{j}$.\\
es: $T(i) = ALBERTO$, $U(j) = PIERO$.\\
\textbf{Soluzione}\\
$LCS(T(i), U(j))$ = $LCS(T(i-1), U(j-1))$ $\oplus$ $t_{i}$\\
nel caso dell'esempio mostrato sopra:\\
$LCS(ALBERTO, PIERO)$ = $LCS(ALBERT, PIER)$ $\oplus$ O
	\item \textbf{Caso 2:}\\
Si considerino due prefissi $T(i)$ e $U(j)$ tali per cui il loro ultimo carattere è differente: $t_{i} \neq u_{j}$.\\
es: $T(i) = ALBERT$, $U(j) = PIER$.\\
\textbf{Soluzione}\\
$LCS(T(i), U(j))$ = $longest(LCS(T(i-1), U(j)), LCS(T(i), U(j-1)))$\\
nel caso dell'esempio mostrato sopra:\\
$LCS(ALBERTO, PIERO)$ = $longest (LCS(ALBER, PIER), LCS(ALBERT, PIE))$\\
\end{itemize}
\textbf{Casi Base}\\
La più lunga sottosequenza tra $T(i)$ e $U(j)$ quando uno dei due è vuoto è $LCS(T(i), U(0))$ = $\emptyset$\\\\
\textbf{Formula Completa}\\
\begin{equation*}
  	LCS(T(i), U(j)) =\begin{cases}
    	\emptyset & \text{$i = 0$ or $j=0$}\\
    	LCS(T(i-1), U(j-1)) \oplus t_{i} & \text{$i>0$ and $j>0$ and $t_{i} = u_{j}$}\\
    	longest(LCS(T(i-1), U(j)), LCS(T(i), U(j-1))) & \text{$i>0$ and $j>0$ and $t_{i} \neq u_{j}$}
    	
  	\end{cases}
\end{equation*}\\\\
\textbf{Lunghezza della LCS}\\
Date due sequenze $T$ e $U$ di lunghezza $n$ e $m$, scrivere una formula ricorsiva $DP[i][j]$ che restituisca la \textcolor{red}{lunghezza} della LCS dei prefissi $T(i)$ e $U(j)$.

\begin{equation*}
  	DP[i][j] =\begin{cases}
    	0 & \text{$i = 0$ or $j=0$}\\
    	DP[i-1][j-1] + 1 & \text{$i>0$ and $j>0$ and $t_{i} = u_{j}$}\\
    	max \{DP[i-1][j], DP[i][j-1]\} & \text{$i>0$ and $j>0$ and $t_{i} \neq u_{j}$}
    	
  	\end{cases}
\end{equation*}
L'informazione relativa alla lunghezza della LCS del problema si troverà in $DP[n][m]$.\\\\
\textbf{Esempio funzionamento soluzione e struttura dati}\\
La tabella seguente mostra la struttura dati che sarà presente in memoria dopo aver eseguit o l'algoritmo sulle strighe ATBCBD e TACCBT. La freccia che punta verso il basso vuol dire che l'elemento è stato ricavato dall'elemento presente sulla stessa colonna della tabella, ma sulla riga precedente, la freccia che punta verso destra che l'elemento proviene dalla stessa riga ma dalla colonna precedente, mentre la freccia diagonale che l'elemento è stato calcolato a partire dall'elemento sulla riga e sulla colonna precedente. 

\begin{center}
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{ |c|c|c|c|c|c|c|c|c| } 
		\hline
			&j &0 &1 &2 &3 &4 &5 &6\\
		\hline
			i & & &A &T &B &C &B &D\\
		\hline
			0 & &0 &0 &0 &0 &0 &0 &0\\
		\hline
			1 &T &0 & $\downarrow$ 0 & $\searrow$ 1 & $\rightarrow$ 1 & $\rightarrow$ 1 & $\rightarrow$ 1 & $\rightarrow$ 1\\
		\hline
			2 &A &0 & $\searrow$ 1 & $\downarrow$ 1 & $\downarrow$ 1 & $\downarrow$ 1 & $\downarrow$ 1 & $\downarrow$ 1\\
		\hline
			3 &C &0 & $\downarrow$ 1 & $\downarrow$ 1 & $\downarrow$ 1 & $\searrow$ 2 & $\rightarrow$ 2 & $\rightarrow$ 2\\
		\hline
			4 &C &0 & $\downarrow$ 1 & $\downarrow$ 1 & $\downarrow$ 1 & $\searrow$ 2 & $\downarrow$ 2 & $\rightarrow$ 2\\
		\hline
			5 &B &0 & $\downarrow$ 1 & $\downarrow$ 1 & $\searrow$ 2 & $\downarrow$ 2 & $\searrow$ 3 & $\rightarrow$ 3\\
		\hline
			6 &T &0 & $\downarrow$ 1 & $\searrow$ 2 & $\downarrow$ 2 & $\downarrow$ 2 & $\downarrow$ 3 & $\downarrow$ 3\\
			\hline
	\end{tabular}
\end{center}
Il risultato dell'esempio lo troviamo nella tabella in posizione [6,6] e vale 3. L'insieme delle soluzioni (cioè le lettere appartenenti alla sottosequenza massima) possono essere ricavate seguendo le frecce nella presenti nella struttura dati.\\\\
\textbf{Implementazione ricorrenza}
\begin{lstlisting}[caption= Lunghezza LCS]
int lcs(int[] T, int[] U, int n, int m)
	int[][] DP = new int[0...n][0...m]
	for i = 0 to n do
		for j = 0 to n do
			if i = 0 or j = 0 then
				DP[i][j] = 0
	for i = 1 to n do
		for j = 1 to m do
			if T[i] == U[j] then
				DP[i][j] = DP[i-1][j-1] + 1
			else
				DP[i][j] = max(DP[i-1][j], DP[i][j-1])
	return DP[n][m]
\end{lstlisting}
Nel caso in cui si voglia invece restituire la sottosequenza comune è invece necessario usare un algoritmo di questo tipo:
\begin{lstlisting}[caption=Ricostruire LCS]
LIST lcs(int[] T, int[] U, int n, int m)
	...
	return subsequence(DP, T, U, n, m)
	
LIST subsequence(int[][] DP, ITEM[] T, ITEM[] U, int i, int j)
	if i== 0 or j==0 then
		return List()
	if T[i]==U[j] then
		S = subsequence(DP, T, U, i-1, j-1)
		S.insert(S.head(), T[i])
		return S
	else
		if DP[i-1][j] > DP[i][j-1] then
			return subsequence(DP, T, U, i-1, j)
		else
			return subsequence(DP, T, U, i, j-1)
\end{lstlisting}
La complessità computazionale di subsequence è al massimo $T(n) = \mathcal{O}(m+n)$ che  corrisponde al numero massimo di controlli che verranno eseguiti per ricostituire la soluzione, mentre il costo per creare e riempire la matrice è pari a $T(n) = \mathcal{O}(mn)$. In totale il costo di LCS è pari a $T(n) = \mathcal{O}(mn)$.

\newpage
\end{document}