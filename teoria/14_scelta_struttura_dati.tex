\documentclass[../cheatSheetAlgoritmi.tex]{subfiles}
\begin{document}

\section{Scelta della struttura dati}
\subsection{Il problema dei cammini minimi a sorgente singola}
Il problema dei cammini minimi che andremo ad affrontare prevede un pattern comune per una serie di algoritmi diversi tra loro, dove, cambiando solamente la struttura dati di riferimento, è possibile ottenere soluzioni con caratteristiche e complessità differenti.
\\\\
\textbf{Introduzione al problema} \\
In input verrà ricevuto: 
\begin{itemize}
	\item  Grafo orientato $G = (V, E)$
	\item Un nodo sorgente $s$
	\item Una funzione di peso $w \mid E \rightarrow R$
\end{itemize} 
Dato un cammino $p = (v_1, v_2, .. , v_k)$ con $k > 1$, il costo del cammino è dato da 
\begin{equation*}
	w(p) = \sum_{i = 2}^{k} w(v_{i-1}, v_i)
\end{equation*}
Ci è richiesto di trovare un cammino da $s$ ad $u$, per ogni nodo $u \in V$, il cui costo sia minimo, ovvero più piccolo o uguale del costo di qualunque altro cammino da $s$ ad $u$.
\\\\
\textbf{Nota sui pesi degli archi} \\
Algoritmi differenti possono funzionare o meno in presenza di alcune categorie speciali di pesi:
\begin{itemize}
\item Positivi / positivi + negativi
\item Reali / Interi
\end{itemize}
Si noti inoltre che il problema per come è stato posto precedentemente accetta pesi negativi, ma tuttavia non è possibile avere dei cicli la cui somma sia negativa, in quanto non esisterebbe un cammino minimo, dato che per diminuire il costo del cammino è sufficiente ripercorrere tali archi.
\\\\
\textbf{Soluzione ammissibile} \\
Una soluzione ammissibile può essere descritta da un albero di copertura $T$ radicato in $s$ e da un vettore di distanze $d$, i cui valori $d[u]$ rappresentano il costo del cammino da $s$ a $u$ in $T$
\\\\
\textbf{Il teorema di Bellman} \\
Una soluzione ammissibile $T$ è ottima se e solo se:
\begin{itemize}
	\item $d[v] = d[u] +w(u, v)$ per ogni arco $(u, v) \in T$
	\item $d[v] \leq d[u] +w(u, v)$ per ogni arco $(u, v) \in E$
\end{itemize}
\textbf{Algoritmo generico} \\
In seguito verrà mostrato un pattern generico per la risoluzione del problema dei cammini minimi che, in base alla struttura dati utilizzata e alle opportune modifiche che verranno apportate alle righe contrassegnate da (1), (2), (3) e (4), non solo cambierà la complessità legata all'algoritmo, ma inoltre risulteranno differenti le proprietà dello stesso, il quale si comporterà in maniera differente in base all'input fornito.
\begin{lstlisting}[caption=Algoritmo generico per il problema dei cammini minimi a sorgente singola]
(int[],int[]) shortestPath (Graph G, Node s)
	int[] d = new int[1... G.n]		%d[u] := la distanza da s a u 
	int[] T = new int[1... G.n]		%T[u] := padre di u in T
	boolean[] b = new boolean[1... G.n]	%b[u] := true se u presente in S 
	foreach u $\in$ G.V() - {s} do
		T[u] = nil
		d[u] = $+\infty$
		b[u] = false
	T[s] = nil
	d[s] = 0
	b[s] = true
	DataStructure S = DataStructure()	 %(1)
	S.add(s)
	while not S.isEmpty() do 
		int u = S.extract() 	%(2)
		b[u] = false
		foreach v $\in$ G.adj(u) do
			if d[u] + G.w(u, v) < d[v] then 
				if not b[v] then
					S.add(v)	%(3)
					b[v] = true
				else
					%Azione da svolgere nel caso v sia presente in S (4)
				T[v] = u 
				d[v] = d[u] + G.w(u, v)
	return(T, d)
\end{lstlisting}
\textbf{Algoritmo di Dijkstra, 1959} \\
Algoritmo che fa uso come struttura dati di una coda a priorità basata su vettore, esso funziona bene solamente con i pesi positivi ed ha un costo computazionale di $\mathcal{O}(n^2)$ per via del metodo $deleteMin()$ che ha una compessità di $\mathcal{O}(n)$, richiamato per ogni nodo del grafo.
\begin{lstlisting}[caption=Algoritmo di Edsger W. Dijkstra: cammini minimi a sorgente singola]
(int[],int[]) shortestPath (Graph G, Node s)
	int[] d = new int[1... G.n]		%d[u] := la distanza da s a u 
	int[] T = new int[1... G.n]		%T[u] := padre di u in T
	boolean[] b = new boolean[1... G.n]	%b[u] := true se u presente in S 
	foreach u $\in$ G.V() - {s} do
		T[u] = nil
		d[u] = $+\infty$
		b[u] = false
	T[s] = nil
	d[s] = 0
	b[s] = true
	PriorityQueue Q = PriorityQueue();	%Basata su un vettore (1)
	Q.insert(s,0)
	while not Q.isEmpty() do 
		int u = Q.deleteMin()	%Deve scorrrere tutti gli elementi del vettore (2)
		b[u] = false
		foreach v $\in$ G.adj(u) do
			if d[u] + G.w(u, v) < d[v] then 
				if not b[v] then
					Q.insert(v, d[u] + G.w(u, v)) %Semplice modifica del valore con costo costante (3)
					b[v] = true
				else
					Q.decrease(v, d[u] + G.w(u, v)) %Semplice modifica del valore con costo costante (4)
				T[v] = u 
				d[v] = d[u] + G.w(u, v)
	return(T, d)
\end{lstlisting}
Importante è osservare che:
\begin{itemize}
	\item Ogni nodo viene estratto una e una sola volta;
	\item Al momento dell’estrazione la sua distanza è minima.
\end{itemize}
Queste due proprietà, che sono dimostrabili per induzione, consentono di verificare la correttezza dell'algoritmo di Dijkstra. \\
Un altra proprietà degna di nota è di essere ottimale per il calcolo di cammini minimi a sorgente singola per grafi densi, ovvero grafi il cui numero di archi $m$ sia $\Omega(n^2)$, in quanto la complessità di questo non dipende dal numero di archi.
Un analisi più dettagliata sulla complessità:
\\\\
\begin{tabular}{@{}lllll@{}}
\toprule
Riga & Costo & Ripetizioni &  &  \\ \midrule
(1) & $\mathcal{O}(n)$     & 1           &  &  \\
(2)    & $\mathcal{O}(n)$     & $\mathcal{O}(n)$           &  &  \\
(3)    & $\mathcal{O}(1)$     & $\mathcal{O}(n)$           &  &  \\
(4)    & $\mathcal{O}(1)$     & $\mathcal{O}(n)$           &  &  \\ \bottomrule
\end{tabular}
\\\\
Costo totale: $\mathcal{O}(n^2)$ \\\\
\textbf{Algoritmo di Johnson, 1977} \\
Variante dell'algoritmo di Dijkstra che fa utilizzo di una coda a priorità  basata su heap binario e non più su vettore.
\begin{lstlisting}[caption=Algoritmo di Johnson: cammini minimi a sorgente singola]
(int[],int[]) shortestPath (Graph G, Node s)
	int[] d = new int[1... G.n]		%d[u] := la distanza da s a u 
	int[] T = new int[1... G.n]		%T[u] := padre di u in T
	boolean[] b = new boolean[1... G.n]	%b[u] := true se u presente in S 
	foreach u $\in$ G.V() - {s} do
		T[u] = nil
		d[u] = $+\infty$
		b[u] = false
	T[s] = nil
	d[s] = 0
	b[s] = true
	PriorityQueue Q = PriorityQueue();	%Basata su heap binario(1)
	Q.insert(s,0)
	while not Q.isEmpty() do 
		int u = Q.deleteMin()	%Di costo logaritmico (2)
		b[u] = false
		foreach v $\in$ G.adj(u) do
			if d[u] + G.w(u, v) < d[v] then 
				if not b[v] then
					Q.insert(v, d[u] + G.w(u, v)) %Di costo logaritmico (3)
					b[v] = true
				else
					Q.decrease(v, d[u] + G.w(u, v)) %Di costo logaritmico (4)
				T[v] = u 
				d[v] = d[u] + G.w(u, v)
	return(T, d)
\end{lstlisting}
Utilizzando una coda priorità basata su heap binario, le proprietà dell'algoritmo mostrato confrontate con quello di Dijkstra presentano delle leggere differenze, nonostante entrambi funzionino solamente per archi di peso positivo. \\
Si ha che l'algoritmo mostrato ha le seguenti caratteristiche:
\begin{itemize}
	\item Ha una complessità differente: $\mathcal{O}(m \log n)$
	\item Funziona particolarmente bene per i grafi sparsi, ovvero grafi che presentano un limitato numero di archi.
	Per grafi densi, la complessità precedente supererebbe quello di Dijkstra, infatti in questo caso si avrebbe: $m$ è $\Omega(n^2)$, dunque $\mathcal{O}(m \log n) 	\approx \mathcal{O}(n^2 \log n) >  \mathcal{O}(n^2)$, mentre per grafi che presentano un numero ridotto di archi tale che $m$ è $\mathcal{O}(n)$, il costo computazionale viene approssimato a $\mathcal{O}(n \log n)$.
\end{itemize}
Analisi della complessità:
\\\\
\begin{tabular}{@{}lllll@{}}
\toprule
Riga & Costo & Ripetizioni &  &  \\ \midrule
(1) & $\mathcal{O}(n)$     & 1           &  &  \\
(2)    & $\mathcal{O}(\log n)$     & $\mathcal{O}(n)$           &  &  \\
(3)    & $\mathcal{O}(\log n)$     & $\mathcal{O}(n)$           &  &  \\
(4)    & $\mathcal{O}(\log n)$     & $\mathcal{O}(m)$           &  &  \\ \bottomrule
\end{tabular}
\\\\
Dal quale risulta un costo totale di $\mathcal{O}(m \log n)$ \\\\
\textbf{Algoritmo di Fredman-Tarjan, 1987} \\
Algoritmo ancora una volta basato su code a priorità, in questo caso però implementate con heap di Fibonacci, una struttura dati complessa che permette di ammortizzare il costo dell'operazione di decrease, ottenendo dunque un costo computazionale differente rispetto ai precedenti due algoritmi.
\begin{lstlisting}[caption=Algoritmo di Fredman-Tarjan: cammini minimi a sorgente singola]
(int[],int[]) shortestPath (Graph G, Node s)
	int[] d = new int[1 ... G.n]		%d[u] := la distanza da s a u 
	int[] T = new int[1... G.n]		%T[u] := padre di u in T
	boolean[] b = new boolean[1... G.n]	%b[u] := true se u presente in S 
	foreach u $\in$ G.V() - {s} do
		T[u] = nil
		d[u] = $+\infty$
		b[u] = false
	T[s] = nil
	d[s] = 0
	b[s] = true
	PriorityQueue Q = PriorityQueue();	%Basato su heap di Fibonacci (1)
	Q.insert(s,0)
	while not Q.isEmpty() do 
		int u = Q.deleteMin()	%Di costo logaritmico (2)
		b[u] = false
		foreach v $\in$ G.adj(u) do
			if d[u] + G.w(u, v) < d[v] then 
				if not b[v] then
					Q.insert(v, d[u] + G.w(u, v)) %Di costo logaritmico (3)
					b[v] = true
				else
					Q.decrease(v, d[u] + G.w(u, v)) %Di costo ammortizzato costante (4)
				T[v] = u 
				d[v] = d[u] + G.w(u, v)
	return(T, d)
\end{lstlisting}
Questo algoritmo, nonostante presenti una complessità relativamente bassa, soffre di fattori moltiplicativi delle varie operazioni abbastanza alte dovute alla gestione della coda con priorità. Questo infatti lo rende un algoritmo giustificabile e perfetto per grafi densi e di dimensioni molto grandi. Per grafi di piccole dimensioni invece si preferisce fare uso degli algoritmi visti in precedenza.\\\\
Analisi della complessità:
\\\\
\begin{tabular}{@{}lllll@{}}
\toprule
Riga & Costo & Ripetizioni &  &  \\ \midrule
(1) & $\mathcal{O}(n)$     & 1           &  &  \\
(2)    & $\mathcal{O}(\log n)$     & $\mathcal{O}(n)$           &  &  \\
(3)    & $\mathcal{O}(\log n)$     & $\mathcal{O}(n)$           &  &  \\
(4)    & $\mathcal{O}(1)^{(*)}$     & $\mathcal{O}(m)$           &  &  \\ \bottomrule
\end{tabular}
\\\\
Dal quale risulta un costo totale di $\mathcal{O}(m + n \log n)$, dove $^{(*)}$ indica che il costo è derivato da un analisi ammortizzata. \\\\
\textbf{Algoritmo di Bellman-Ford-Moore, 1958} \\
Algoritmo basato su una coda, senza priorità, computazionalmente più pesante rispetto all'algoritmo di Dijkstra, che permette però di gestire i grafi con archi di peso negativo.
\begin{lstlisting}[caption=Algoritmo di Bellman-Ford-Moore: cammini minimi a sorgente singola]
(int[],int[]) shortestPath (Graph G, Node s)
	int[] d = new int[1... G.n]		%d[u] := la distanza da s a u 
	int[] T = new int[1... G.n]		%T[u] := padre di u in T
	boolean[] b = new boolean[1... G.n]	%b[u] := true se u presente in S 
	foreach u $\in$ G.V() - {s} do
		T[u] = nil
		d[u] = $+\infty$
		b[u] = false
	T[s] = nil
	d[s] = 0
	b[s] = true
	Queue Q = Queue();	%Coda (1)
	Q.insert(s,0)
	Q.enqueue(s)
	while not S.isEmpty() do 
		int u = Q.dequeue()	%Costo costante (2)
		b[u] = false
		foreach v $\in$ G.adj(u) do
			if d[u] + G.w(u, v) < d[v] then 
				if not b[v] then
					Q.enqueue(v) %Costo costante (3)
					b[v] = true
				T[v] = u 
				d[v] = d[u] + G.w(u, v)
	return(T, d)
\end{lstlisting}
A differenza degli algoritmi precedenti questo algoritmo funziona per grafi con archi che possiedono un peso negativo, a discapito però di una maggiore complessità. \\ Per studiare la complessità dell'algoritmo di Bellman-Ford-Moore è necessario parlare di passate; sostanzialmente in questo algoritmo un nodo può essere inserito nuovamente in coda, dopo essere stato già rimosso, a differenza degli algoritmi precedenti i cui nodi venivano estratti una singola volta per poi non essere più accodati; ad ogni estrazione infatti, che chiamiamo passata, vengono estratti i nodi il cui costo descrive i cammini minimi di lunghezza pari al numero di passata (dove la passata zeresima consiste con l'estrazione della sorgente) . Le passate si ripeteranno per un massimo di (n-1), nelle quali vegono ogni volta analizzati dei percorsi migliori che descrivono cammini di lughezza al più n - 1. \\\\
Il costo computazionale è dunque:
\\\\
\begin{tabular}{@{}lllll@{}}
\toprule
Riga & Costo & Ripetizioni &  &  \\ \midrule
(1) & $\mathcal{O}(1)$     & 1           &  &  \\
(2)    & $\mathcal{O}(1)$     & $\mathcal{O}(n^2)$           &  &  \\
(3)    & $\mathcal{O}(1)$     & $\mathcal{O}(nm)$           &  &  \\ \bottomrule
\end{tabular}
\\\\
Dal quale risulta un costo totale di $\mathcal{O}(mn)$, dato dal fatto che ogni nodo può essere inserito ed estratto al massimo n-1 volte. \\\\
\textbf{Cammini minimi su DAG} \\
Algoritmo basato su uno stack che contiene i nodi che fanno parte dell'ordinamento topologico a partire dalla sorgente. Si basa sul fatto che, se sappiamo che il grafo in questione non possiede cicli, non c’è modo di tornare su un nodo già visitato e abbassare il suo costo.
\begin{lstlisting}[caption=Algoritmo per i DAG: cammini minimi a sorgente singola]
(int[],int[]) shortestPath (Graph G, Node s)
	int[] d = new int[1... G.n]		%d[u] := la distanza da s a u 
	int[] T = new int[1... G.n]		%T[u] := padre di u in T
	foreach u $\in$ G.V() - {s} do
		T[u] = nil
		d[u] = $+\infty$
	T[s] = nil
	d[s] = 0
	STACK S = topsort(G)
	while not S.isEmpty() do 
		int u = S.pop()
		foreach v $\in$ G.adj(u) do
			if d[u] + G.w(u, v) < d[v] then 
				T[v] = u 
				d[v] = d[u] + G.w(u, v)
	return(T, d)
\end{lstlisting}
La complessità dell'algoritmo precedente è dunque di $\mathcal{O}(n + m)$ in quanto è una semplice visita BFS del grafo. \\\\
\textbf{Riassumendo, che algoritmo preferire?} \\\\
\begin{tabular}{lllll}
Dijkstra       &  $O(n^2)$ & Pesi positivi, grafi densi &  \\
Johnson        &  $O(m \log n)$ &  Pesi positivi, grafi sparsi &  \\
Fredman-Tarjan &  $O(n + n \log n)$ & Pesi positivi, grafi densi,dimensioni molto grandi  & \\
Bellman-Ford-Moore &  $O(mn)$ & Pesi negativi &  \\
DAG               & $O(mn)$ & DAG  &  \\
BFS	 & $O(mn)$ & Senza pesi &  \\
\end{tabular}\\\\
La soluzione che fa uso della BFS è sostanzialmente l'algoritmo di Erdos introdotto qualche capitolo fa.

\subsection{Il problema dei cammini minimi a sorgente multipla}
\textbf{Possibili soluzioni} \\\\
\begin{tabular}{@{}lllll@{}}
\toprule
Input & Complessità & Approccio &  &  \\ \midrule

Pesi positivi, grafo denso       &  $O(n \cdot n^2)$ & Applicazione ripetuta dell’algoritmo di Dijkstra &  \\

Pesi positivi, grafo sparso        &  $O(n \cdot (m \log n))$ &  Applicazione ripetuta dell’algoritmo di Johnson &  \\

Pesi negativi &  $O(n \cdot nm)$ & Applicazione ripetuta di Bellman-Ford-Moore, sconsigliata & \\

Pesi negativi, grafo denso &  $O(n^3)$ & Algoritmo di Floyd e Warshall &  \\

Pesi negativi, grafo sparso               & $O(nm \log n)$ & Algoritmo di Johnson per sorgente multipla  &  \\ \bottomrule
\end{tabular}\\\\\\
\textbf{Algoritmo di Floyd-Warshall, 1962} \\
Algoritmo basato sulla programmazione dinamica per il calcolo dei cammini minimi a sorgente multipla. Il problema che si pone è sostanzialmente quello precedente con l'unica variante che, invece di mantenere un unica sorgente e trovare tutti i cammini minimi dalla stessa agli altri nodi, si vuole fare questo processo per ogni vertice del grafo.  \\
Si definiscono dei termini utili per la comprensione dell'algoritmo: \\\\
\textbf{Assunzione}  \\
Assumiamo che esista un ordinamento fra i nodi del grafo $v_1 , v_2 , ... , v_n$. \\\\
\textbf{I cammini minimi k-vincolati} \\
Sia k un valore in ${0, ...,  n}$. Diciamo che un cammino $p^{k}_{xy}$ è un
cammino minimo k-vincolato fra $x$ e $y$ se esso ha il costo minimo fra tutti i cammini fra $x$ e $y$ che non passano per nessun vertice in $v_{k+1} , . . . , v_n$ ($x$ e $y$ sono esclusi dal vincolo). \\\\
\textbf{Distanza k-vincolata} \\
Denotiamo con $d^{k}[x][y]$ il costo totale del cammino minimo k-vincolato fra $x$ e $y$, se esiste.
\[
  d^{k}[x][y]=\begin{cases}
               w(p^{k}_{xy}) & \text{se esiste }p^{k}_{xy}\\
               +\infty & \text{altrimenti}
            \end{cases}
\]
\textbf{Matrice dei padri} \\
Oltre a definire la matrice $d$, calcoliamo una matrice T dove $T[x][y]$ rappresenta il predecessore di y nel cammino più breve da $x$ a $y$. \\\\
\textbf{Principio di funzionamento} \\
L'algoritmo di Floyd-Warshall è basato sulla definizione di cammino minimo k-vincolato, sostanzialmente per ogni coppia di veritici si osserva il comportamento in seguito all'aggiunta di un nuovo nodo dal quale i cammini possono passare, l'aggiunta di tale vertice può o meno diminuire la distanza tra i nodi in questione. Si parte infatti con i cammini minimi 0 vincolati, i quali rappresentano tutti i possibili cammini che non passano per alcun vertice, ad eccezione dei nodi adiacenti, ovvero gli archi diretti. Mano a mano che si considerano nuovi nodi i costi possono modificarsi; la soluzione finale si troverà  una volta analizzati i cammini n-vincolati, in quanto sono i cammini di costo minimo che possono passare per qualunque vertice del grafo. \\
Ciò che abbiamo definito fino ad ora può essere riassunto dalla seguente ricorrenza: \\
\[
  d^{k}[x][y]=\begin{cases}
               w(x, y) & k = 0\\
               min(d^{k-1}[x][y], d^{k-1}[x][k] + d^{k-1}[x][y]) & k > 0
            \end{cases}
\]
\begin{lstlisting}[caption=Algoritmo di Floyd e Warshall cammini minimi a sorgente multipla]
(int[],int[]) floydWarshall (Graph G)
	int[][] d = new int[1...n][1...n]
	int[][] T = new int[1...n][1...n]
	foreach u, v $\in$ G.V() do
		d[u][v] = +$\infty$
		T[u][v] = nil
	foreach u $\in$ G.V() do
		foreach v $\in$ G.adj(u) do
			d[u][v] = G.w(u, v)
			T[u][v] = u
	for k = 1 to G.n do
		foreach u $\in$ G.V() do
			foreach v $\in$ G.V() do
				if d[u][k] + d[k][v] < d[u][v] then
					d[u][v] = d[u][k] + d[k][v]
					T[u][v] = T[k][v]
	return (T,d)
\end{lstlisting}
La prima parte dell'algoritmo si occupa della trasformazione del nostro grafo, che abbiamo sempre assunto essere espresso mediante liste di adiacenza, in un grafo rappresentato da una matrice di adiacenza. Una volta fatto questo, si fissa il parametro k (che rapprensenta il vincolo del cammino preso in analisi), e per ogni coppia di nodi si verificano i percorsi migliori facendo le opportune modifiche sul costo. \\
La complessità totale dell'algoritmo è $\mathcal{O}(n^3)$ dovuta alla presenza di tre cicli for annidati che iterano sui nodi del grafo.
\end{document}
